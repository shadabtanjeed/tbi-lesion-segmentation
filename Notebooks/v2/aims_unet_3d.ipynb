{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c3eb479",
   "metadata": {},
   "source": [
    "To run the notebook on different machine, you need to adjust the following:\n",
    "- Original preprocessed data directory\n",
    "- Create 3 directories for ```nnUNet_raw```, ```nnUNet_preprocessed```, and ```nnUNet_results```\n",
    "- Correct directory for nnunet raw in  ```create_nnunet_dataset_structure()``` function\n",
    "- Correct directory in env variables\n",
    "- Pick up the correct env variable export cell for your platform (Linux or Windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5a0e4b",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "822e05d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Using cached numpy-2.3.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Collecting nibabel\n",
      "  Using cached nibabel-5.3.2-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.16.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (61 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting plotly\n",
      "  Downloading plotly-6.3.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting optuna\n",
      "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting SimpleITK\n",
      "  Using cached simpleitk-2.5.2-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.2 kB)\n",
      "Collecting hiddenlayer\n",
      "  Downloading hiddenlayer-0.3-py3-none-any.whl.metadata (703 bytes)\n",
      "Collecting torch\n",
      "  Using cached torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: packaging>=20 in /home/shadab/Github_Repos/tbi-lesion-segmentation/aims_venv/lib/python3.12/site-packages (from nibabel) (25.0)\n",
      "Collecting typing-extensions>=4.6 (from nibabel)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.59.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (109 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.7/109.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/shadab/Github_Repos/tbi-lesion-segmentation/aims_venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting narwhals>=1.15.1 (from plotly)\n",
      "  Using cached narwhals-2.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.16.5-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
      "  Downloading sqlalchemy-2.0.43-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting PyYAML (from optuna)\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting setuptools (from torch)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
      "  Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.3 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
      "  Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.4.0 (from torch)\n",
      "  Using cached triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/shadab/Github_Repos/tbi-lesion-segmentation/aims_venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna)\n",
      "  Downloading greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Using cached numpy-2.3.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "Using cached nibabel-5.3.2-py3-none-any.whl (3.3 MB)\n",
      "Using cached matplotlib-3.10.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "Using cached pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "Using cached scipy-1.16.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.2 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading plotly-6.3.0-py3-none-any.whl (9.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached simpleitk-2.5.2-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (52.6 MB)\n",
      "Downloading hiddenlayer-0.3-py3-none-any.whl (19 kB)\n",
      "Using cached torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl (887.9 MB)\n",
      "Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "Using cached nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Using cached triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
      "Downloading alembic-1.16.5-py3-none-any.whl (247 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.4/247.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.59.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "Using cached narwhals-2.2.0-py3-none-any.whl (401 kB)\n",
      "Using cached pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Downloading sqlalchemy-2.0.43-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Using cached filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Using cached fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (767 kB)\n",
      "Downloading greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (607 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m607.6/607.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: SimpleITK, pytz, nvidia-cusparselt-cu12, mpmath, hiddenlayer, tzdata, typing-extensions, tqdm, sympy, setuptools, PyYAML, pyparsing, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, narwhals, MarkupSafe, kiwisolver, greenlet, fsspec, fonttools, filelock, cycler, colorlog, triton, sqlalchemy, scipy, plotly, pandas, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nibabel, Mako, jinja2, contourpy, nvidia-cusolver-cu12, matplotlib, alembic, torch, optuna\n",
      "Successfully installed Mako-1.3.10 MarkupSafe-3.0.2 PyYAML-6.0.2 SimpleITK-2.5.2 alembic-1.16.5 colorlog-6.9.0 contourpy-1.3.3 cycler-0.12.1 filelock-3.19.1 fonttools-4.59.2 fsspec-2025.7.0 greenlet-3.2.4 hiddenlayer-0.3 jinja2-3.1.6 kiwisolver-1.4.9 matplotlib-3.10.5 mpmath-1.3.0 narwhals-2.2.0 networkx-3.5 nibabel-5.3.2 numpy-2.3.2 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 optuna-4.5.0 pandas-2.3.2 pillow-11.3.0 plotly-6.3.0 pyparsing-3.2.3 pytz-2025.2 scipy-1.16.1 setuptools-80.9.0 sqlalchemy-2.0.43 sympy-1.14.0 torch-2.8.0 tqdm-4.67.1 triton-3.4.0 typing-extensions-4.15.0 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy nibabel matplotlib pandas scipy tqdm plotly optuna SimpleITK hiddenlayer torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c105ccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581fc97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install causal-conv1d mamba-ssm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493a7713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip uninstall torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a9c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed43dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# must be done after installing pytorch\n",
    "# ! pip install nnunetv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0156401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! git clone https://github.com/MrBlankness/LightM-UNet\n",
    "# ! cd LightM-UNet/lightm-unet\n",
    "# ! pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a5f368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shadab/Github_Repos/tbi-lesion-segmentation/aims_venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from scipy.ndimage import zoom, rotate\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from matplotlib.widgets import Slider\n",
    "import plotly.graph_objects as go\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import SimpleITK as sitk\n",
    "import subprocess\n",
    "import shutil\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d475b1e7",
   "metadata": {},
   "source": [
    "## Dataset Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0af49c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images_dir = r\"F:\\aims_tbi\\normalized_T1_scans\"\n",
    "masks_dir = r\"F:\\aims_tbi\\resampled_1mm_Lesion_masks\"\n",
    "\n",
    "\n",
    "# print number of files in processed images and masks\n",
    "print(f\"Number of processed images: {len(os.listdir(images_dir))}\")\n",
    "print(f\"Number of processed masks: {len(os.listdir(masks_dir))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61919533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define scan parameters\n",
    "scan_id = 'scan_0001'\n",
    "start_slice = 110\n",
    "num_slices = 5\n",
    "\n",
    "# Load the .nii.gz files\n",
    "image_path = os.path.join(images_dir, f\"{scan_id}_T1_normalized.nii.gz\")\n",
    "mask_path = os.path.join(masks_dir, f\"{scan_id}_Lesion_resampled_1mm.nii.gz\")\n",
    "\n",
    "# Load image and mask using nibabel\n",
    "image_nii = nib.load(image_path)\n",
    "mask_nii = nib.load(mask_path)\n",
    "\n",
    "image_array = image_nii.get_fdata().astype(np.float32)\n",
    "mask_array = mask_nii.get_fdata().astype(np.uint8)\n",
    "\n",
    "print(f\"Loaded {scan_id}:\")\n",
    "print(f\"Image shape: {image_array.shape}\")\n",
    "print(f\"Mask shape: {mask_array.shape}\")\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(2, num_slices, figsize=(num_slices * 3, 10))\n",
    "\n",
    "# Ensure axes is 2D even for single slice\n",
    "if num_slices == 1:\n",
    "    axes = axes.reshape(-1, 1)\n",
    "\n",
    "for i in range(num_slices):\n",
    "    slice_idx = start_slice + i\n",
    "\n",
    "    # Check if slice index is valid\n",
    "    if slice_idx >= image_array.shape[2]:\n",
    "        print(f\"⚠️ Slice {slice_idx} is out of bounds (max: {image_array.shape[2]-1}), skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Extract slices (transpose for proper orientation)\n",
    "    image_slice = image_array[:, :, slice_idx].T\n",
    "    mask_slice = mask_array[:, :, slice_idx].T\n",
    "\n",
    "    # Row 1: Processed T1 image only\n",
    "    axes[0, i].imshow(image_slice, cmap='gray', origin='lower')\n",
    "    axes[0, i].set_title(f'Processed T1\\n(Normalized) Slice {slice_idx}', fontsize=10)\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "    # Row 2: Processed T1 + Lesion overlay\n",
    "    axes[1, i].imshow(image_slice, cmap='gray', origin='lower')\n",
    "    if np.any(mask_slice > 0):  # Only overlay if there are lesions in this slice\n",
    "        axes[1, i].imshow(mask_slice, cmap='Reds', alpha=0.6, origin='lower')\n",
    "    axes[1, i].set_title(f'Processed T1 + Lesion\\nSlice {slice_idx}', fontsize=10)\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(f'Processed Images from NIfTI Files - {scan_id}', fontsize=16, y=0.98)\n",
    "plt.show()\n",
    "\n",
    "# Print intensity statistics\n",
    "print(f\"\\n=== Statistics from NIfTI Files for {scan_id} ===\")\n",
    "\n",
    "# Image stats (brain voxels only)\n",
    "brain_mask = image_array != 0  # Background is 0 after normalization\n",
    "brain_voxels = image_array[brain_mask]\n",
    "\n",
    "print(\"Processed T1 Image (from NIfTI file):\")\n",
    "print(f\"  Mean: {np.mean(brain_voxels):.6f}\")\n",
    "print(f\"  Std: {np.std(brain_voxels):.6f}\")\n",
    "print(f\"  Min: {np.min(brain_voxels):.4f}\")\n",
    "print(f\"  Max: {np.max(brain_voxels):.4f}\")\n",
    "print(f\"  Shape: {image_array.shape}\")\n",
    "\n",
    "# Lesion statistics\n",
    "lesion_voxels = np.count_nonzero(mask_array)\n",
    "total_voxels = mask_array.size\n",
    "lesion_percentage = (lesion_voxels / total_voxels) * 100\n",
    "\n",
    "print(f\"\\nLesion Mask (from NIfTI file):\")\n",
    "print(f\"  Lesion voxels: {lesion_voxels:,}\")\n",
    "print(f\"  Total voxels: {total_voxels:,}\")\n",
    "print(f\"  Lesion percentage: {lesion_percentage:.4f}%\")\n",
    "print(f\"  Shape: {mask_array.shape}\")\n",
    "\n",
    "# If you have metadata, you can print it here (optional)\n",
    "# print(f\"\\nMetadata Statistics:\")\n",
    "# print(f\"  Brain voxels: ...\")\n",
    "# print(f\"  Brain mean: ...\")\n",
    "# print(f\"  Brain std: ...\")\n",
    "# print(f\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cdc0a6",
   "metadata": {},
   "source": [
    "### Verify the mask values are limited to 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd565b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fname in os.listdir(masks_dir):\n",
    "#     if fname.endswith(\"_Lesion_resampled_1mm.nii.gz\"):\n",
    "#         mask_path = os.path.join(masks_dir, fname)\n",
    "#         mask_array = nib.load(mask_path).get_fdata().astype(np.uint8)\n",
    "#         unique_vals = np.unique(mask_array)\n",
    "#         if np.any((unique_vals != 0) & (unique_vals != 1)):\n",
    "#             print(f\"{fname}: {unique_vals}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6cb538",
   "metadata": {},
   "source": [
    "## 3D-UNet setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32af8033",
   "metadata": {},
   "source": [
    "### Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daae93a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LesionDataset(Dataset):\n",
    "    def __init__(self, images_dir, masks_dir, transform=None):\n",
    "        self.images = sorted([f for f in os.listdir(images_dir) if f.endswith('.nii.gz')])\n",
    "        self.masks = sorted([f for f in os.listdir(masks_dir) if f.endswith('.nii.gz')])\n",
    "        self.images_dir = images_dir\n",
    "        self.masks_dir = masks_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.images_dir, self.images[idx])\n",
    "        mask_path = os.path.join(self.masks_dir, self.masks[idx])\n",
    "        image = nib.load(img_path).get_fdata().astype(np.float32)\n",
    "        mask = nib.load(mask_path).get_fdata().astype(np.uint8)\n",
    "        # Add channel dimension\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        mask = np.expand_dims(mask, axis=0)\n",
    "        return torch.from_numpy(image), torch.from_numpy(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c875a6",
   "metadata": {},
   "source": [
    "### 3D U-Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d4b365",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, init_features=32):\n",
    "        super(UNet3D, self).__init__()\n",
    "        features = init_features\n",
    "        self.encoder1 = self._block(in_channels, features)\n",
    "        self.pool1 = nn.MaxPool3d(2)\n",
    "        self.encoder2 = self._block(features, features*2)\n",
    "        self.pool2 = nn.MaxPool3d(2)\n",
    "        self.encoder3 = self._block(features*2, features*4)\n",
    "        self.pool3 = nn.MaxPool3d(2)\n",
    "        self.encoder4 = self._block(features*4, features*8)\n",
    "        self.pool4 = nn.MaxPool3d(2)\n",
    "\n",
    "        self.bottleneck = self._block(features*8, features*16)\n",
    "\n",
    "        self.up4 = nn.ConvTranspose3d(features*16, features*8, 2, stride=2)\n",
    "        self.decoder4 = self._block(features*16, features*8)\n",
    "        self.up3 = nn.ConvTranspose3d(features*8, features*4, 2, stride=2)\n",
    "        self.decoder3 = self._block(features*8, features*4)\n",
    "        self.up2 = nn.ConvTranspose3d(features*4, features*2, 2, stride=2)\n",
    "        self.decoder2 = self._block(features*4, features*2)\n",
    "        self.up1 = nn.ConvTranspose3d(features*2, features, 2, stride=2)\n",
    "        self.decoder1 = self._block(features*2, features)\n",
    "\n",
    "        self.conv = nn.Conv3d(features, out_channels, kernel_size=1)\n",
    "\n",
    "    def _block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "        enc3 = self.encoder3(self.pool2(enc2))\n",
    "        enc4 = self.encoder4(self.pool3(enc3))\n",
    "\n",
    "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
    "\n",
    "        dec4 = self.up4(bottleneck)\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        dec3 = self.up3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.up2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.up1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        return torch.sigmoid(self.conv(dec1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2063dd85",
   "metadata": {},
   "source": [
    "### Dice Metric Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909b278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score(pred, target, epsilon=1e-6):\n",
    "    pred = (pred > 0.5).float()\n",
    "    target = target.float()\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum()\n",
    "    dice = (2. * intersection + epsilon) / (union + epsilon)\n",
    "    return dice.item()\n",
    "\n",
    "def dice_per_class(pred, target, epsilon=1e-6):\n",
    "    pred = (pred > 0.5).float()\n",
    "    target = target.float()\n",
    "    # Lesion (positive)\n",
    "    dice_lesion = dice_score(pred, target, epsilon)\n",
    "    # Background (negative)\n",
    "    dice_bg = dice_score(1 - pred, 1 - target, epsilon)\n",
    "    # Overall (mean)\n",
    "    dice_overall = (dice_lesion + dice_bg) / 2\n",
    "    return dice_lesion, dice_bg, dice_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ac4588",
   "metadata": {},
   "source": [
    "Loss Function (Dice + BCE for Imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cffefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bce = nn.BCELoss()\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.view(-1)\n",
    "        target = target.view(-1)\n",
    "        dice = 1 - dice_score(pred, target)\n",
    "        bce = self.bce(pred, target)\n",
    "        return dice + bce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccca360",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1352973f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Dataset and DataLoader\n",
    "dataset = LesionDataset(images_dir, masks_dir)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_ds, val_ds = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=1)\n",
    "\n",
    "# Model, Loss, Optimizer\n",
    "model = UNet3D().to(device)\n",
    "criterion = DiceBCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training\n",
    "num_epochs = 50\n",
    "best_val_dice = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, masks in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    dice_lesion, dice_bg, dice_overall = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\"):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            val_loss += loss.item()\n",
    "            d_lesion, d_bg, d_overall = dice_per_class(outputs, masks)\n",
    "            dice_lesion += d_lesion\n",
    "            dice_bg += d_bg\n",
    "            dice_overall += d_overall\n",
    "    val_loss /= len(val_loader)\n",
    "    dice_lesion /= len(val_loader)\n",
    "    dice_bg /= len(val_loader)\n",
    "    dice_overall /= len(val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}, Dice Lesion={dice_lesion:.4f}, Dice BG={dice_bg:.4f}, Dice Overall={dice_overall:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if dice_lesion > best_val_dice:\n",
    "        best_val_dice = dice_lesion\n",
    "        torch.save(model.state_dict(), \"3dunet_model_new_preprocessing.pth\")\n",
    "        print(\"Saved best model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397121e3",
   "metadata": {},
   "source": [
    "### Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f822e9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load model for inference\n",
    "# model = UNet3D().to(device)\n",
    "# model.load_state_dict(torch.load(\"best_3dunet_model.pth\"))\n",
    "# model.eval()\n",
    "\n",
    "# # Example inference on a single scan\n",
    "# with torch.no_grad():\n",
    "#     img, _ = dataset[0]\n",
    "#     img = img.unsqueeze(0).to(device)\n",
    "#     pred = model(img)\n",
    "#     pred_mask = (pred > 0.5).cpu().numpy().astype(np.uint8)[0,0]\n",
    "#     # Save as NIfTI\n",
    "#     nib.save(nib.Nifti1Image(pred_mask, np.eye(4)), \"predicted_mask.nii.gz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aims_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
