{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c3eb479",
   "metadata": {},
   "source": [
    "To run the notebook on different machine, you need to adjust the following:\n",
    "- Original preprocessed data directory\n",
    "- Create 3 directories for ```nnUNet_raw```, ```nnUNet_preprocessed```, and ```nnUNet_results```\n",
    "- Correct directory for nnunet raw in  ```create_nnunet_dataset_structure()``` function\n",
    "- Correct directory in env variables\n",
    "- Pick up the correct env variable export cell for your platform (Linux or Windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5a0e4b",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822e05d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install numpy nibabel matplotlib pandas torch scipy tqdm plotly optuna SimpleITK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed43dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# must be done after installing pytorch\n",
    "! pip install nnunetv2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a5f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from scipy.ndimage import zoom\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from matplotlib.widgets import Slider\n",
    "import plotly.graph_objects as go\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "from scipy.ndimage import rotate\n",
    "import optuna\n",
    "\n",
    "from optuna.pruners import MedianPruner\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import SimpleITK as sitk\n",
    "\n",
    "import subprocess\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import shutil\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d475b1e7",
   "metadata": {},
   "source": [
    "## Dataset Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0af49c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_dir = \"E:\\\\AIMS_Data\\\\final_processed_data\\\\final_processed_data\\\\pytorch_individual\"\n",
    "\n",
    "images_dir = os.path.join(processed_data_dir, \"images\")\n",
    "masks_dir = os.path.join(processed_data_dir, \"masks\")\n",
    "metadata_dir = os.path.join(processed_data_dir, \"metadata\")\n",
    "\n",
    "# print number of files in processed images and masks\n",
    "print(f\"Number of processed images: {len(os.listdir(images_dir))}\")\n",
    "print(f\"Number of processed masks: {len(os.listdir(masks_dir))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61919533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define scan parameters\n",
    "scan_id = 'scan_0001'\n",
    "start_slice = 110\n",
    "num_slices = 5\n",
    "\n",
    "# Load the .pt files\n",
    "image_path = os.path.join(images_dir, f\"{scan_id}_image.pt\")\n",
    "mask_path = os.path.join(masks_dir, f\"{scan_id}_mask.pt\")\n",
    "metadata_path = os.path.join(metadata_dir, f\"{scan_id}_metadata.json\")\n",
    "\n",
    "# Load image tensor\n",
    "image_data = torch.load(image_path, map_location='cpu')\n",
    "image_tensor = image_data['image']  # Shape: [1, H, W, D]\n",
    "\n",
    "# Load mask tensor\n",
    "mask_data = torch.load(mask_path, map_location='cpu')\n",
    "mask_tensor = mask_data['mask']  # Shape: [1, H, W, D]\n",
    "\n",
    "# Load metadata\n",
    "with open(metadata_path, 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# Remove channel dimension for visualization: [H, W, D]\n",
    "image_array = image_tensor.squeeze(0).numpy()\n",
    "mask_array = mask_tensor.squeeze(0).numpy()\n",
    "\n",
    "print(f\"Loaded {scan_id}:\")\n",
    "print(f\"Image tensor shape: {image_tensor.shape}\")\n",
    "print(f\"Mask tensor shape: {mask_tensor.shape}\")\n",
    "print(f\"Has lesion: {metadata['statistics']['has_lesion']}\")\n",
    "print(f\"Lesion voxels: {metadata['statistics']['lesion_voxels']:,}\")\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(2, num_slices, figsize=(num_slices * 3, 10))\n",
    "\n",
    "# Ensure axes is 2D even for single slice\n",
    "if num_slices == 1:\n",
    "    axes = axes.reshape(-1, 1)\n",
    "\n",
    "for i in range(num_slices):\n",
    "    slice_idx = start_slice + i\n",
    "    \n",
    "    # Check if slice index is valid\n",
    "    if slice_idx >= image_array.shape[2]:\n",
    "        print(f\"‚ö†Ô∏è Slice {slice_idx} is out of bounds (max: {image_array.shape[2]-1}), skipping...\")\n",
    "        continue\n",
    "    \n",
    "    # Extract slices (transpose for proper orientation)\n",
    "    image_slice = image_array[:, :, slice_idx].T\n",
    "    mask_slice = mask_array[:, :, slice_idx].T\n",
    "    \n",
    "    # Row 1: Processed T1 image only\n",
    "    axes[0, i].imshow(image_slice, cmap='gray', origin='lower')\n",
    "    axes[0, i].set_title(f'Processed T1\\n(Normalized) Slice {slice_idx}', fontsize=10)\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Row 2: Processed T1 + Lesion overlay\n",
    "    axes[1, i].imshow(image_slice, cmap='gray', origin='lower')\n",
    "    if np.any(mask_slice > 0):  # Only overlay if there are lesions in this slice\n",
    "        axes[1, i].imshow(mask_slice, cmap='Reds', alpha=0.6, origin='lower')\n",
    "    axes[1, i].set_title(f'Processed T1 + Lesion\\nSlice {slice_idx}', fontsize=10)\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(f'Processed Images from .pt Files - {scan_id}', fontsize=16, y=0.98)\n",
    "plt.show()\n",
    "\n",
    "# Print intensity statistics\n",
    "print(f\"\\n=== Statistics from .pt Files for {scan_id} ===\")\n",
    "\n",
    "# Image stats (brain voxels only)\n",
    "brain_mask = image_array != 0  # Background is 0 after normalization\n",
    "brain_voxels = image_array[brain_mask]\n",
    "\n",
    "print(\"Processed T1 Image (from .pt file):\")\n",
    "print(f\"  Mean: {np.mean(brain_voxels):.6f}\")\n",
    "print(f\"  Std: {np.std(brain_voxels):.6f}\")\n",
    "print(f\"  Min: {np.min(brain_voxels):.4f}\")\n",
    "print(f\"  Max: {np.max(brain_voxels):.4f}\")\n",
    "print(f\"  Shape: {image_array.shape}\")\n",
    "\n",
    "# Lesion statistics\n",
    "lesion_voxels = np.count_nonzero(mask_array)\n",
    "total_voxels = mask_array.size\n",
    "lesion_percentage = (lesion_voxels / total_voxels) * 100\n",
    "\n",
    "print(f\"\\nLesion Mask (from .pt file):\")\n",
    "print(f\"  Lesion voxels: {lesion_voxels:,}\")\n",
    "print(f\"  Total voxels: {total_voxels:,}\")\n",
    "print(f\"  Lesion percentage: {lesion_percentage:.4f}%\")\n",
    "print(f\"  Shape: {mask_array.shape}\")\n",
    "\n",
    "# Metadata statistics\n",
    "print(f\"\\nMetadata Statistics:\")\n",
    "print(f\"  Brain voxels: {metadata['statistics']['brain_voxels']:,}\")\n",
    "print(f\"  Brain mean: {metadata['statistics']['brain_mean']:.6f}\")\n",
    "print(f\"  Brain std: {metadata['statistics']['brain_std']:.6f}\")\n",
    "print(f\"  Image range: [{metadata['statistics']['image_range'][0]:.4f}, {metadata['statistics']['image_range'][1]:.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cdc0a6",
   "metadata": {},
   "source": [
    "### Verify the mask values are limited to 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd565b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_dir = r\"E:\\AIMS_Data\\final_processed_data\\final_processed_data\\pytorch_individual\\masks\"\n",
    "\n",
    "for fname in os.listdir(masks_dir):\n",
    "    if fname.endswith(\"_mask.pt\"):\n",
    "        mask_data = torch.load(os.path.join(masks_dir, fname), map_location='cpu')\n",
    "        mask_array = mask_data['mask'].squeeze(0).numpy()\n",
    "        unique_vals = np.unique(mask_array)\n",
    "        if np.any(unique_vals > 1):\n",
    "            print(f\"{fname}: {unique_vals}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6cb538",
   "metadata": {},
   "source": [
    "## nnUNet setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d62bbb",
   "metadata": {},
   "source": [
    "### Dataset conversion for nnUNet compatibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a66e57",
   "metadata": {},
   "source": [
    "Create nnU-Net Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5073519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nnunet_dataset_structure():\n",
    "    \"\"\"Create nnU-Net compatible dataset structure\"\"\"\n",
    "    \n",
    "    # Set your nnUNet_raw path (adjust as needed)\n",
    "    nnunet_raw = \"E:/AIMS_Data/nnUNet_raw\"  # or your path\n",
    "    dataset_name = \"Dataset600_TBILesion\"  # Choose an unused ID\n",
    "    \n",
    "    dataset_path = os.path.join(nnunet_raw, dataset_name)\n",
    "    \n",
    "    # Create directories\n",
    "    os.makedirs(os.path.join(dataset_path, \"imagesTr\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dataset_path, \"labelsTr\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dataset_path, \"imagesTs\"), exist_ok=True)  # Optional for test data\n",
    "    \n",
    "    return dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a8efc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path = create_nnunet_dataset_structure()\n",
    "# print(f\"Created dataset structure at: {dataset_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7c532c",
   "metadata": {},
   "source": [
    "Convert Your .pt Files to nnU-Net Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946ff199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pt_to_nnunet_format(processed_data_dir, dataset_path, train_ratio=0.85):\n",
    "    \"\"\"Enhanced conversion that saves test labels separately for evaluation\"\"\"\n",
    "    \n",
    "    images_dir = os.path.join(processed_data_dir, \"images\")\n",
    "    masks_dir = os.path.join(processed_data_dir, \"masks\")\n",
    "    metadata_dir = os.path.join(processed_data_dir, \"metadata\")\n",
    "    \n",
    "    # Get all scan IDs\n",
    "    image_files = [f for f in os.listdir(images_dir) if f.endswith('_image.pt')]\n",
    "    scan_ids = [f.replace('_image.pt', '') for f in image_files]\n",
    "    \n",
    "    print(f\"Found {len(scan_ids)} scans to convert\")\n",
    "    \n",
    "    # Stratified split to ensure lesion cases in both train/test\n",
    "    # Load metadata to check for lesions\n",
    "    lesion_scans = []\n",
    "    no_lesion_scans = []\n",
    "    \n",
    "    for scan_id in scan_ids:\n",
    "        metadata_path = os.path.join(metadata_dir, f\"{scan_id}_metadata.json\")\n",
    "        with open(metadata_path, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        \n",
    "        if metadata['statistics']['has_lesion']:\n",
    "            lesion_scans.append(scan_id)\n",
    "        else:\n",
    "            no_lesion_scans.append(scan_id)\n",
    "    \n",
    "    print(f\"Lesion scans: {len(lesion_scans)}\")\n",
    "    print(f\"No-lesion scans: {len(no_lesion_scans)}\")\n",
    "    \n",
    "    # Stratified split\n",
    "    n_train_lesion = int(len(lesion_scans) * train_ratio)\n",
    "    n_train_no_lesion = int(len(no_lesion_scans) * train_ratio)\n",
    "    \n",
    "    train_ids = lesion_scans[:n_train_lesion] + no_lesion_scans[:n_train_no_lesion]\n",
    "    test_ids = lesion_scans[n_train_lesion:] + no_lesion_scans[n_train_no_lesion:]\n",
    "    \n",
    "    print(f\"Training scans: {len(train_ids)}\")\n",
    "    print(f\"Test scans: {len(test_ids)}\")\n",
    "    \n",
    "    # Create separate directory for test labels (for evaluation)\n",
    "    test_labels_dir = os.path.join(dataset_path, \"test_labels_for_evaluation\")\n",
    "    os.makedirs(test_labels_dir, exist_ok=True)\n",
    "    \n",
    "    converted_count = 0\n",
    "    metadata_preserved = []\n",
    "    \n",
    "    for split, ids in [(\"Tr\", train_ids), (\"Ts\", test_ids)]:\n",
    "        for scan_id in ids:\n",
    "            try:\n",
    "                # Load data\n",
    "                image_path = os.path.join(images_dir, f\"{scan_id}_image.pt\")\n",
    "                mask_path = os.path.join(masks_dir, f\"{scan_id}_mask.pt\")\n",
    "                metadata_path = os.path.join(metadata_dir, f\"{scan_id}_metadata.json\")\n",
    "                \n",
    "                image_data = torch.load(image_path, map_location='cpu')\n",
    "                mask_data = torch.load(mask_path, map_location='cpu')\n",
    "                \n",
    "                with open(metadata_path, 'r') as f:\n",
    "                    metadata = json.load(f)\n",
    "                \n",
    "                # Extract arrays\n",
    "                image_array = image_data['image'].squeeze(0).numpy().astype(np.float32)\n",
    "                mask_array = mask_data['mask'].squeeze(0).numpy().astype(np.uint8)\n",
    "\n",
    "                unique_vals = np.unique(mask_array)\n",
    "                if np.any((unique_vals != 0) & (unique_vals != 1)):\n",
    "                    print(f\"Warning: {scan_id} has unexpected mask values: {unique_vals}. Remapping all >1 to 1.\")\n",
    "                    mask_array[mask_array > 1] = 1\n",
    "                \n",
    "                # Create affine matrix\n",
    "                if 'spacing' in metadata:\n",
    "                    spacing = metadata['spacing']\n",
    "                    affine = np.diag([spacing[0], spacing[1], spacing[2], 1.0])\n",
    "                else:\n",
    "                    affine = np.eye(4)\n",
    "                \n",
    "                # Create NIfTI images\n",
    "                image_nii = nib.Nifti1Image(image_array, affine)\n",
    "                mask_nii = nib.Nifti1Image(mask_array, affine)\n",
    "                \n",
    "                # Preserve some metadata in NIfTI header\n",
    "                if 'statistics' in metadata:\n",
    "                    stats = metadata['statistics']\n",
    "                    description = f\"Lesion:{stats.get('has_lesion', False)},LesionVox:{stats.get('lesion_voxels', 0)}\"\n",
    "                    image_nii.header['descrip'] = description.encode()[:79]\n",
    "                \n",
    "                # Save images\n",
    "                image_filename = f\"{scan_id}_0000.nii.gz\"\n",
    "                image_save_path = os.path.join(dataset_path, f\"images{split}\", image_filename)\n",
    "                nib.save(image_nii, image_save_path)\n",
    "                \n",
    "                # Save masks\n",
    "                mask_filename = f\"{scan_id}.nii.gz\"\n",
    "                if split == \"Tr\":\n",
    "                    # Training labels go to labelsTr (nnU-Net requirement)\n",
    "                    mask_save_path = os.path.join(dataset_path, \"labelsTr\", mask_filename)\n",
    "                    nib.save(mask_nii, mask_save_path)\n",
    "                else:\n",
    "                    # Test labels go to separate folder for evaluation\n",
    "                    mask_save_path = os.path.join(test_labels_dir, mask_filename)\n",
    "                    nib.save(mask_nii, mask_save_path)\n",
    "                \n",
    "                # Preserve metadata\n",
    "                metadata_preserved.append({\n",
    "                    'scan_id': scan_id,\n",
    "                    'split': split,\n",
    "                    'original_metadata': metadata,\n",
    "                    'file_paths': {\n",
    "                        'image': image_save_path,\n",
    "                        'mask': mask_save_path\n",
    "                    }\n",
    "                })\n",
    "                \n",
    "                converted_count += 1\n",
    "                \n",
    "                if converted_count % 50 == 0:\n",
    "                    print(f\"Converted {converted_count} scans...\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error converting {scan_id}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata_file = os.path.join(dataset_path, \"preserved_metadata.json\")\n",
    "    with open(metadata_file, 'w') as f:\n",
    "        json.dump(metadata_preserved, f, indent=2)\n",
    "    \n",
    "    # Save test scan list for evaluation\n",
    "    test_scans_file = os.path.join(dataset_path, \"test_scan_ids.json\")\n",
    "    with open(test_scans_file, 'w') as f:\n",
    "        json.dump(test_ids, f, indent=2)\n",
    "    \n",
    "    print(f\"Successfully converted {converted_count} scans\")\n",
    "    print(f\"Test labels saved to: {test_labels_dir}\")\n",
    "    print(f\"Test scan IDs saved to: {test_scans_file}\")\n",
    "    print(f\"Preserved metadata saved to: {metadata_file}\")\n",
    "    \n",
    "    return len(train_ids), len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc0aae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert your data\n",
    "# n_train, n_test = convert_pt_to_nnunet_format(processed_data_dir, dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7365ef5",
   "metadata": {},
   "source": [
    "Create dataset.json File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12c02a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_json(dataset_path, num_training):\n",
    "    \"\"\"Create dataset.json file for nnU-Net\"\"\"\n",
    "    \n",
    "    dataset_json = {\n",
    "        \"channel_names\": {\n",
    "            \"0\": \"T1\"  # Your T1-weighted MRI scans\n",
    "        },\n",
    "        \"labels\": {\n",
    "            \"background\": 0,\n",
    "            \"lesion\": 1\n",
    "        },\n",
    "        \"numTraining\": num_training,\n",
    "        \"file_ending\": \".nii.gz\",\n",
    "        \"dataset_name\": \"TBI_Lesion_Segmentation\",\n",
    "        \"reference\": \"AIMS TBI Challenge\",\n",
    "        \"licence\": \"Your License\",\n",
    "        \"description\": \"Traumatic Brain Injury Lesion Segmentation Dataset\"\n",
    "    }\n",
    "    \n",
    "    # Save dataset.json\n",
    "    json_path = os.path.join(dataset_path, \"dataset.json\")\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(dataset_json, f, indent=2)\n",
    "    \n",
    "    print(f\"Created dataset.json with {num_training} training cases\")\n",
    "    print(f\"Saved to: {json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8438d987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_dataset_json(dataset_path, n_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efe8077",
   "metadata": {},
   "source": [
    "Verify Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe8436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_dataset_structure(dataset_path):\n",
    "    \"\"\"Verify the dataset structure is correct\"\"\"\n",
    "    \n",
    "    print(\"Verifying dataset structure...\")\n",
    "    \n",
    "    # Check folder structure\n",
    "    required_folders = [\"imagesTr\", \"labelsTr\"]\n",
    "    for folder in required_folders:\n",
    "        folder_path = os.path.join(dataset_path, folder)\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\"‚ùå Missing folder: {folder}\")\n",
    "            return False\n",
    "        else:\n",
    "            print(f\"‚úÖ Found folder: {folder}\")\n",
    "    \n",
    "    # Check dataset.json\n",
    "    json_path = os.path.join(dataset_path, \"dataset.json\")\n",
    "    if not os.path.exists(json_path):\n",
    "        print(\"‚ùå Missing dataset.json\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"‚úÖ Found dataset.json\")\n",
    "    \n",
    "    # Check file counts\n",
    "    images_tr = len([f for f in os.listdir(os.path.join(dataset_path, \"imagesTr\")) if f.endswith('.nii.gz')])\n",
    "    labels_tr = len([f for f in os.listdir(os.path.join(dataset_path, \"labelsTr\")) if f.endswith('.nii.gz')])\n",
    "    \n",
    "    print(f\"Training images: {images_tr}\")\n",
    "    print(f\"Training labels: {labels_tr}\")\n",
    "    \n",
    "    if images_tr != labels_tr:\n",
    "        print(\"‚ùå Mismatch between number of images and labels\")\n",
    "        return False\n",
    "    \n",
    "    # Check file naming convention\n",
    "    sample_files = os.listdir(os.path.join(dataset_path, \"imagesTr\"))[:5]\n",
    "    for file in sample_files:\n",
    "        if not file.endswith('_0000.nii.gz'):\n",
    "            print(f\"‚ùå Incorrect naming: {file} (should end with _0000.nii.gz)\")\n",
    "            return False\n",
    "    \n",
    "    print(\"‚úÖ Dataset structure verification passed!\")\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdda8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify_dataset_structure(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcc877d",
   "metadata": {},
   "source": [
    "Complete Dataset Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806be055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete conversion script\n",
    "def convert_tbi_dataset_to_nnunet():\n",
    "    \"\"\"Complete conversion from your .pt format to nnU-Net format\"\"\"\n",
    "    \n",
    "    \n",
    "    # Step 1: Create dataset structure\n",
    "    dataset_path = create_nnunet_dataset_structure()\n",
    "    \n",
    "    # Step 2: Convert data\n",
    "    n_train, n_test = convert_pt_to_nnunet_format(processed_data_dir, dataset_path)\n",
    "    \n",
    "    # Step 3: Create dataset.json\n",
    "    create_dataset_json(dataset_path, n_train)\n",
    "    \n",
    "    # Step 4: Verify structure\n",
    "    if verify_dataset_structure(dataset_path):\n",
    "        print(\"\\nüéâ Dataset successfully converted to nnU-Net format!\")\n",
    "        print(f\"Dataset location: {dataset_path}\")\n",
    "        print(\"\\nNext steps:\")\n",
    "        print(\"1. Set your environment variables\")\n",
    "        print(\"2. Run: nnUNetv2_plan_and_preprocess -d 600 --verify_dataset_integrity\")\n",
    "        print(\"3. Run: nnUNetv2_train 600 3d_fullres 0 --npz\")\n",
    "    else:\n",
    "        print(\"‚ùå Dataset conversion failed!\")\n",
    "\n",
    "# Run the conversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6199707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_tbi_dataset_to_nnunet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f5ef7b",
   "metadata": {},
   "source": [
    "### env variable setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0619258d",
   "metadata": {},
   "source": [
    "For Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b815df7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! export nnUNet_raw=\"/media/fabian/nnUNet_raw\"\n",
    "# ! export nnUNet_preprocessed=\"/media/fabian/nnUNet_preprocessed\"\n",
    "# ! export nnUNet_results=\"/media/fabian/nnUNet_results\"\n",
    "# ! export nnUNet_n_proc_DA=12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebc0b99",
   "metadata": {},
   "source": [
    "For windows (PowerShell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b419437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['nnUNet_raw'] = \"E:/AIMS_Data/nnUNet_raw\"\n",
    "os.environ['nnUNet_preprocessed'] = \"E:/AIMS_Data/nnUNet_preprocessed\"\n",
    "os.environ['nnUNet_results'] = \"E:/AIMS_Data/nnUNet_results\"\n",
    "os.environ['nnUNet_n_proc_DA'] = \"12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7de1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the environment variables are set\n",
    "print(\"Environment variables set:\")\n",
    "print(f\"nnUNet_raw: {os.environ.get('nnUNet_raw')}\")\n",
    "print(f\"nnUNet_preprocessed: {os.environ.get('nnUNet_preprocessed')}\")\n",
    "print(f\"nnUNet_results: {os.environ.get('nnUNet_results')}\")\n",
    "print(f\"nnUNet_n_proc_DA: {os.environ.get('nnUNet_n_proc_DA')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c21d990",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fe0fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! nnUNetv2_plan_and_preprocess -d 600 --verify_dataset_integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053fcf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for fold 0; repeat for folds 1‚Äì4\n",
    "! nnUNetv2_train 600 3d_fullres 0 --npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7058749",
   "metadata": {},
   "outputs": [],
   "source": [
    "! nnUNetv2_train 600 3d_fullres 1 --npz\n",
    "! nnUNetv2_train 600 3d_fullres 2 --npz\n",
    "! nnUNetv2_train 600 3d_fullres 3 --npz\n",
    "! nnUNetv2_train 600 3d_fullres 4 --npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e423cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "! nnUNetv2_export_model_to_zip --dataset 600 --config 3d_fullres\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aims_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
