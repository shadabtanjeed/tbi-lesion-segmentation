{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "706b1751",
   "metadata": {
    "id": "706b1751"
   },
   "source": [
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FLwYEcD9oDFe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:34.797009Z",
     "iopub.status.busy": "2025-06-28T21:11:34.796225Z",
     "iopub.status.idle": "2025-06-28T21:11:41.574376Z",
     "shell.execute_reply": "2025-06-28T21:11:41.573403Z",
     "shell.execute_reply.started": "2025-06-28T21:11:34.796980Z"
    },
    "id": "FLwYEcD9oDFe",
    "outputId": "c2050048-3240-49ef-d8a3-86e892da8cce",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install ipympl\n",
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf53e352",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:41.576403Z",
     "iopub.status.busy": "2025-06-28T21:11:41.575886Z",
     "iopub.status.idle": "2025-06-28T21:11:47.179608Z",
     "shell.execute_reply": "2025-06-28T21:11:47.178874Z",
     "shell.execute_reply.started": "2025-06-28T21:11:41.576378Z"
    },
    "id": "bf53e352",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install nibabel matplotlib\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import drive\n",
    "import pandas as pd\n",
    "import torch\n",
    "from scipy.ndimage import zoom\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from matplotlib.widgets import Slider\n",
    "import plotly.graph_objects as go\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "from scipy.ndimage import rotate\n",
    "import optuna\n",
    "\n",
    "from optuna.pruners import MedianPruner\n",
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db90865d",
   "metadata": {
    "id": "db90865d"
   },
   "source": [
    "## Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f486fde",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:47.180636Z",
     "iopub.status.busy": "2025-06-28T21:11:47.180310Z",
     "iopub.status.idle": "2025-06-28T21:11:47.184296Z",
     "shell.execute_reply": "2025-06-28T21:11:47.183505Z",
     "shell.execute_reply.started": "2025-06-28T21:11:47.180620Z"
    },
    "id": "8f486fde",
    "outputId": "eb29251e-1877-4aa1-c3de-1d979ee60a8e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Mount Google Drive to access dataset files\n",
    "# drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3af37c0",
   "metadata": {
    "id": "e3af37c0"
   },
   "source": [
    "## Load NIfTI Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82733ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:47.186566Z",
     "iopub.status.busy": "2025-06-28T21:11:47.186360Z",
     "iopub.status.idle": "2025-06-28T21:11:47.231807Z",
     "shell.execute_reply": "2025-06-28T21:11:47.230943Z",
     "shell.execute_reply.started": "2025-06-28T21:11:47.186549Z"
    },
    "id": "e82733ce",
    "outputId": "cd02393f-01fa-42fc-8b8c-fe0ddf2dfe16",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define data path and list NIfTI (.nii) files\n",
    "data_path = \"/kaggle/input/aims-tbs-challenge-files/ChallengeFiles\"\n",
    "file_list = sorted([f for f in os.listdir(data_path) if f.endswith('.nii')])\n",
    "\n",
    "print(f\"Found {len(file_list)} nii files\")\n",
    "print(file_list[:5])  # Show first 5 files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11f1f66",
   "metadata": {
    "id": "a11f1f66"
   },
   "source": [
    "## Read Sample NIfTI File & Normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AeXMRGh-K2IN",
   "metadata": {
    "id": "AeXMRGh-K2IN"
   },
   "source": [
    "- .nii file are 3d images\n",
    "- consider slices as the 2d images stacked together to create a 3d one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0545875",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:47.232692Z",
     "iopub.status.busy": "2025-06-28T21:11:47.232509Z",
     "iopub.status.idle": "2025-06-28T21:11:47.409354Z",
     "shell.execute_reply": "2025-06-28T21:11:47.408664Z",
     "shell.execute_reply.started": "2025-06-28T21:11:47.232677Z"
    },
    "id": "e0545875",
    "outputId": "09cd5b7e-6a39-4b13-e131-18f4b72d4f21",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load a sample NIfTI file\n",
    "nii_file = os.path.join(data_path, file_list[0])\n",
    "img = nib.load(nii_file)\n",
    "img_data = img.get_fdata()\n",
    "\n",
    "print(f\"Loaded file: {file_list[1]}\")\n",
    "print(f\"Image shape: {img_data.shape}\")\n",
    "\n",
    "# Intensity normalization function for visualization\n",
    "def normalize_slice(slice_data):\n",
    "    slice_min = slice_data.min()\n",
    "    slice_max = slice_data.max()\n",
    "    if slice_max - slice_min > 0:\n",
    "        return (slice_data - slice_min) / (slice_max - slice_min)\n",
    "    else:\n",
    "        return slice_data  # In case slice is constant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SrPushiOMA5Y",
   "metadata": {
    "id": "SrPushiOMA5Y"
   },
   "source": [
    "### VIsualizing Slices\n",
    "\n",
    "Medical image slices (like MRI or CT scans) are displayed in grayscale, where pixel values are mapped to shades from black (low intensity) to white (high intensity).\n",
    "\n",
    "*   **Black Areas:** Typically represent regions with very low signal intensity. This includes the background (air), air-filled cavities, and certain tissue types depending on the scan method (e.g., bone or CSF in some MRI sequences, air in CT).\n",
    "*   **White/Brighter Areas:** Represent regions with high signal intensity. This includes dense tissues (like bone in CT), certain tissue properties in MRI (like fat in T1-weighted or fluid/edema in T2-weighted), or areas with contrast agent uptake.\n",
    "\n",
    "The contrast between dark and bright areas helps visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89316c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:47.410363Z",
     "iopub.status.busy": "2025-06-28T21:11:47.410120Z",
     "iopub.status.idle": "2025-06-28T21:11:47.885807Z",
     "shell.execute_reply": "2025-06-28T21:11:47.885222Z",
     "shell.execute_reply.started": "2025-06-28T21:11:47.410336Z"
    },
    "id": "f89316c8",
    "outputId": "22285bc2-33d7-491e-a94e-f5af297532e6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_slices = 5\n",
    "fig, axes = plt.subplots(1, num_slices, figsize=(15, 5))\n",
    "\n",
    "# Random unique slice indices from the axial dimension (depth)\n",
    "slice_indices = np.random.choice(img_data.shape[2], size=num_slices, replace=False)\n",
    "slice_indices = np.sort(slice_indices)  # optional: sort for nicer display order\n",
    "\n",
    "for i, slice_idx in enumerate(slice_indices):\n",
    "    slice_img = img_data[:, :, slice_idx].T\n",
    "    norm_img = normalize_slice(slice_img)\n",
    "    axes[i].imshow(norm_img, cmap='gray', origin='lower')\n",
    "    axes[i].set_title(f\"Slice {slice_idx}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VI1gOqmFMZF1",
   "metadata": {
    "id": "VI1gOqmFMZF1"
   },
   "source": [
    "### Visualizing T1 Image with Lesion Mask\n",
    "\n",
    "This code block loads both a T1-weighted MRI image and its corresponding lesion segmentation mask for the same scan. It then displays a series of slices from a specified range, overlaying the lesion mask on top of the T1 image to highlight the location and extent of the lesion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64976d19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:47.886667Z",
     "iopub.status.busy": "2025-06-28T21:11:47.886487Z",
     "iopub.status.idle": "2025-06-28T21:11:49.757086Z",
     "shell.execute_reply": "2025-06-28T21:11:49.756361Z",
     "shell.execute_reply.started": "2025-06-28T21:11:47.886653Z"
    },
    "id": "64976d19",
    "outputId": "4ab74e9b-0417-49c4-d5a0-052df5d4be16",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load both the T1 image and the Lesion mask\n",
    "t1_file = os.path.join(data_path, 'scan_0001_T1.nii')\n",
    "lesion_file = os.path.join(data_path, 'scan_0001_Lesion.nii')\n",
    "\n",
    "t1_img = nib.load(t1_file).get_fdata()\n",
    "lesion_img = nib.load(lesion_file).get_fdata()\n",
    "\n",
    "# User-defined slice range\n",
    "start_slice = 110\n",
    "num_slices = 10\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(num_slices):\n",
    "    slice_idx = start_slice + i\n",
    "    t1_slice = t1_img[:, :, slice_idx].T\n",
    "    lesion_slice = lesion_img[:, :, slice_idx].T\n",
    "\n",
    "    axes[i].imshow(t1_slice, cmap='gray', origin='lower')\n",
    "    axes[i].imshow(lesion_slice, cmap='Reds', alpha=0.6, origin='lower')\n",
    "    axes[i].set_title(f\"Slice {slice_idx}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wM92nmx0Mn0D",
   "metadata": {
    "id": "wM92nmx0Mn0D"
   },
   "source": [
    "### Visualizing Coronal and Sagittal Slices\n",
    "\n",
    "This code block demonstrates how to extract and visualize slices from the 3D image data (`img_data`) along planes other than the standard axial view. Specifically, it shows how to display a coronal slice and a sagittal slice from the middle of the image volume.\n",
    "\n",
    "*   Medical 3D images can be viewed as stacks of 2D slices along different orientations:\n",
    "    *   **Axial (or Transverse) slices:** Imagine slicing the body horizontally, like slicing a loaf of bread. These separate the top from the bottom.\n",
    "    *   **Coronal slices:** Imagine slicing the body vertically from side-to-side, separating the front (anterior) from the back (posterior). This code visualizes a coronal slice.\n",
    "    *   **Sagittal slices:** Imagine slicing the body vertically from front to back, separating the left side from the right side. This code visualizes a sagittal slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aadaa4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 839
    },
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:49.757977Z",
     "iopub.status.busy": "2025-06-28T21:11:49.757766Z",
     "iopub.status.idle": "2025-06-28T21:11:49.923008Z",
     "shell.execute_reply": "2025-06-28T21:11:49.922369Z",
     "shell.execute_reply.started": "2025-06-28T21:11:49.757945Z"
    },
    "id": "0aadaa4c",
    "outputId": "4d142121-2618-40ca-c491-bd9d1569e383",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Coronal slice (YZ plane)\n",
    "slice_idx = img_data.shape[0] // 2\n",
    "coronal_slice = normalize_slice(img_data[slice_idx, :, :].T)\n",
    "plt.imshow(coronal_slice, cmap='gray', origin='lower')\n",
    "plt.title(f\"Coronal slice {slice_idx}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Sagittal slice (XZ plane)\n",
    "slice_idx = img_data.shape[1] // 2\n",
    "sagittal_slice = normalize_slice(img_data[:, slice_idx, :].T)\n",
    "plt.imshow(sagittal_slice, cmap='gray', origin='lower')\n",
    "plt.title(f\"Sagittal slice {slice_idx}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zvZ65pHeMw86",
   "metadata": {
    "id": "zvZ65pHeMw86"
   },
   "source": [
    "### Image Intensity Distribution and Non-Zero Voxels\n",
    "\n",
    "- This code block analyzes the distribution of intensity values within the entire 3D image and calculates the proportion of voxels (3D pixels) that have non-zero intensity values.\n",
    "- This helps understand the overall characteristics of the image data, such as the range of intensities present and how much of the image volume is not just background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fe72ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:49.924042Z",
     "iopub.status.busy": "2025-06-28T21:11:49.923756Z",
     "iopub.status.idle": "2025-06-28T21:11:50.892919Z",
     "shell.execute_reply": "2025-06-28T21:11:50.892154Z",
     "shell.execute_reply.started": "2025-06-28T21:11:49.924017Z"
    },
    "id": "f9fe72ac",
    "outputId": "32b90a6d-9953-4f2c-f072-a7f51cd1064b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.hist(img_data.flatten(), bins=100)\n",
    "plt.title(\"Histogram of image intensities\")\n",
    "plt.show()\n",
    "\n",
    "nonzero_voxels = np.count_nonzero(img_data)\n",
    "total_voxels = img_data.size\n",
    "print(f\"Non-zero voxels: {nonzero_voxels} / {total_voxels} ({100*nonzero_voxels/total_voxels:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_eNSxk6rRBjR",
   "metadata": {
    "id": "_eNSxk6rRBjR"
   },
   "source": [
    "## Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EzRxaPTdRlWH",
   "metadata": {
    "id": "EzRxaPTdRlWH"
   },
   "source": [
    "### Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZtD_tRk7Q6o5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:50.895876Z",
     "iopub.status.busy": "2025-06-28T21:11:50.895654Z",
     "iopub.status.idle": "2025-06-28T21:11:50.900217Z",
     "shell.execute_reply": "2025-06-28T21:11:50.899464Z",
     "shell.execute_reply.started": "2025-06-28T21:11:50.895860Z"
    },
    "id": "ZtD_tRk7Q6o5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def preprocess_scan(scan_path, mask_path=None, target_shape=(128, 128, 128), device='cuda'):\n",
    "#     \"\"\"\n",
    "#     Preprocess T1 scan and mask using PyTorch (GPU-accelerated).\n",
    "\n",
    "#     Loads and preprocesses a T1 MRI scan and optionally a lesion mask.\n",
    "\n",
    "#     Args:\n",
    "#         scan_path (str): Path to the T1-weighted MRI scan (.nii)\n",
    "#         mask_path (str or None): Path to the lesion mask (.nii), if available\n",
    "#         target_shape (tuple): Desired output shape for the scan/mask (D, H, W)\n",
    "#         device (str): Device to perform computations on (e.g., 'cuda' or 'cpu')\n",
    "\n",
    "#     Returns:\n",
    "#         scan_tensor (torch.Tensor): Normalized and resampled scan tensor [1, D, H, W]\n",
    "#         mask_tensor (torch.Tensor or None): Binarized and resampled mask tensor [1, D, H, W]\n",
    "#         stats (dict): Dictionary with scan mean, std, and number of lesion voxels\n",
    "#     \"\"\"\n",
    "#     # === Load scan as NumPy array using nibabel (CPU) ===\n",
    "#     scan_np = nib.load(scan_path).get_fdata().astype(np.float32)  # Shape: [D, H, W]\n",
    "\n",
    "#     # === Normalize scan to range [0, 1] ===\n",
    "#     scan_np = (scan_np - scan_np.min()) / (scan_np.max() - scan_np.min() + 1e-5)\n",
    "\n",
    "#     # === Convert scan to PyTorch tensor and move to GPU ===\n",
    "#     # Add batch and channel dimensions: [1, 1, D, H, W]\n",
    "#     scan_tensor = torch.tensor(scan_np, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "#     # === Resample (resize) scan tensor to target shape using trilinear interpolation ===\n",
    "#     scan_tensor = F.interpolate(scan_tensor, size=target_shape, mode='trilinear', align_corners=False)\n",
    "\n",
    "#     # Remove batch dimension: resulting shape [1, D, H, W]\n",
    "#     scan_tensor = scan_tensor.squeeze(0)\n",
    "\n",
    "#     # === Compute scan statistics ===\n",
    "#     scan_mean = float(scan_tensor.mean())  # Global mean\n",
    "#     scan_std = float(scan_tensor.std())    # Global standard deviation\n",
    "\n",
    "#     # === Initialize outputs for lesion mask ===\n",
    "#     mask_tensor = None\n",
    "#     lesion_voxels = -1  # Default to -1 if no mask is provided\n",
    "\n",
    "#     # === If mask path is provided, process the lesion mask ===\n",
    "#     if mask_path:\n",
    "#         # Load mask as NumPy array and binarize: values will be 0 or 1\n",
    "#         mask_np = nib.load(mask_path).get_fdata().astype(np.uint8)\n",
    "#         mask_np = (mask_np > 0).astype(np.float32)\n",
    "\n",
    "#         # Convert to tensor, add batch/channel dims, and move to GPU\n",
    "#         mask_tensor = torch.tensor(mask_np).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "#         # Resample mask to target shape using nearest neighbor interpolation (preserves binary values)\n",
    "#         mask_tensor = F.interpolate(mask_tensor, size=target_shape, mode='nearest')\n",
    "\n",
    "#         # Remove batch dimension: resulting shape [1, D, H, W]\n",
    "#         mask_tensor = mask_tensor.squeeze(0)\n",
    "\n",
    "#         # Count number of lesion voxels (sum of binary mask)\n",
    "#         lesion_voxels = int(mask_tensor.sum().item())\n",
    "\n",
    "#     # === Collect scan statistics ===\n",
    "#     stats = {\n",
    "#         'scan_mean': scan_mean,\n",
    "#         'scan_std': scan_std,\n",
    "#         'lesion_voxels': lesion_voxels\n",
    "#     }\n",
    "\n",
    "#     return scan_tensor, mask_tensor, stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2995bbe7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:50.901174Z",
     "iopub.status.busy": "2025-06-28T21:11:50.900895Z",
     "iopub.status.idle": "2025-06-28T21:11:50.921939Z",
     "shell.execute_reply": "2025-06-28T21:11:50.921239Z",
     "shell.execute_reply.started": "2025-06-28T21:11:50.901156Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def advanced_preprocess_scan(scan_path, mask_path=None, target_shape=(128, 128, 128), device='cuda'):\n",
    "    \"\"\"\n",
    "    Advanced preprocessing with intensity normalization and augmentation-ready format.\n",
    "    \"\"\"\n",
    "    # Load scan\n",
    "    scan_np = nib.load(scan_path).get_fdata().astype(np.float32)\n",
    "    \n",
    "    # Advanced intensity normalization (Z-score normalization)\n",
    "    # Clip extreme outliers first\n",
    "    p1, p99 = np.percentile(scan_np[scan_np > 0], [1, 99])\n",
    "    scan_np = np.clip(scan_np, p1, p99)\n",
    "    \n",
    "    # Z-score normalization on non-zero voxels\n",
    "    non_zero_mask = scan_np > 0\n",
    "    if non_zero_mask.sum() > 0:\n",
    "        mean_val = scan_np[non_zero_mask].mean()\n",
    "        std_val = scan_np[non_zero_mask].std()\n",
    "        scan_np[non_zero_mask] = (scan_np[non_zero_mask] - mean_val) / (std_val + 1e-8)\n",
    "    \n",
    "    # Convert to tensor and resize\n",
    "    scan_tensor = torch.tensor(scan_np).unsqueeze(0).unsqueeze(0).to(device)\n",
    "    scan_tensor = F.interpolate(scan_tensor, size=target_shape, mode='trilinear', align_corners=False)\n",
    "    scan_tensor = scan_tensor.squeeze(0)\n",
    "    \n",
    "    # Process mask if provided\n",
    "    mask_tensor = None\n",
    "    if mask_path and os.path.exists(mask_path):\n",
    "        mask_np = nib.load(mask_path).get_fdata().astype(np.float32)\n",
    "        mask_np = (mask_np > 0).astype(np.float32)\n",
    "        print(f\"Mask {mask_path} sum: {mask_np.sum()}\")\n",
    "        mask_tensor = torch.tensor(mask_np).unsqueeze(0).unsqueeze(0).to(device)\n",
    "        mask_tensor = F.interpolate(mask_tensor, size=target_shape, mode='nearest')\n",
    "        mask_tensor = mask_tensor.squeeze(0)\n",
    "    \n",
    "    return scan_tensor, mask_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6411389d",
   "metadata": {},
   "source": [
    "Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c22add",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:50.922909Z",
     "iopub.status.busy": "2025-06-28T21:11:50.922667Z",
     "iopub.status.idle": "2025-06-28T21:11:50.942434Z",
     "shell.execute_reply": "2025-06-28T21:11:50.941754Z",
     "shell.execute_reply.started": "2025-06-28T21:11:50.922890Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TBIAugmentation:\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "    \n",
    "    def __len__(self):  # ADD THIS METHOD\n",
    "        return len(self.ids)\n",
    "    \n",
    "    def __call__(self, scan, lesion):\n",
    "        if torch.rand(1) < self.p:\n",
    "            # Random rotation (small angles)\n",
    "            angle = torch.randint(-15, 15, (1,)).item()\n",
    "            scan = self.rotate_3d(scan, angle)\n",
    "            lesion = self.rotate_3d(lesion, angle)\n",
    "        \n",
    "        if torch.rand(1) < self.p:\n",
    "            # Random flip\n",
    "            axis = torch.randint(2, 5, (1,)).item()  # axes 2,3,4 (spatial)\n",
    "            scan = torch.flip(scan, [axis])\n",
    "            lesion = torch.flip(lesion, [axis])\n",
    "        \n",
    "        if torch.rand(1) < self.p:\n",
    "            # Gaussian noise\n",
    "            noise = torch.randn_like(scan) * 0.1\n",
    "            scan = scan + noise\n",
    "        \n",
    "        if torch.rand(1) < self.p:\n",
    "            # Intensity scaling\n",
    "            scale = torch.uniform(0.8, 1.2, (1,)).item()\n",
    "            scan = scan * scale\n",
    "        \n",
    "        return scan, lesion\n",
    "    \n",
    "    def rotate_3d(self, tensor, angle):\n",
    "        # Simple rotation around one axis\n",
    "        return tensor  # Implement based on your needs\n",
    "\n",
    "# Update dataset class\n",
    "class TBI3DSegmentationDataset(Dataset):\n",
    "    def __init__(self, data_dict, transform=None, augment=False):\n",
    "        self.ids = list(data_dict.keys())\n",
    "        self.data = data_dict\n",
    "        self.transform = transform\n",
    "        self.augment = TBIAugmentation() if augment else None\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        scan_id = self.ids[idx]\n",
    "        scan = self.data[scan_id][\"scan\"]\n",
    "        lesion = self.data[scan_id][\"lesion\"]\n",
    "\n",
    "        scan = scan.squeeze().unsqueeze(0)\n",
    "        lesion = lesion.squeeze().unsqueeze(0)\n",
    "\n",
    "        if self.augment:\n",
    "            scan, lesion = self.augment(scan, lesion)\n",
    "\n",
    "        return scan, lesion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8F1G0bu-Rphm",
   "metadata": {
    "id": "8F1G0bu-Rphm"
   },
   "source": [
    "### Process All Files & Detect Noisy Scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QMt8hpRQT5RT",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:50.943335Z",
     "iopub.status.busy": "2025-06-28T21:11:50.943103Z",
     "iopub.status.idle": "2025-06-28T21:11:50.959632Z",
     "shell.execute_reply": "2025-06-28T21:11:50.959085Z",
     "shell.execute_reply.started": "2025-06-28T21:11:50.943318Z"
    },
    "id": "QMt8hpRQT5RT",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "raw_path = \"/kaggle/input/aims-tbs-challenge-files/ChallengeFiles\"\n",
    "save_path = \"./PreprocessedData\"\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fSgHtt2MQ8kN",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:50.960600Z",
     "iopub.status.busy": "2025-06-28T21:11:50.960363Z",
     "iopub.status.idle": "2025-06-28T21:11:51.038864Z",
     "shell.execute_reply": "2025-06-28T21:11:51.038243Z",
     "shell.execute_reply.started": "2025-06-28T21:11:50.960580Z"
    },
    "id": "fSgHtt2MQ8kN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "target_shape = (128, 128, 128)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# === Step 1: Get all scan IDs ===\n",
    "all_files = os.listdir(raw_path)\n",
    "scan_ids = sorted(list(set('_'.join(f.split('_')[:-1]) for f in all_files if f.endswith(\"_T1.nii\"))))\n",
    "\n",
    "# === Step 2: Start preprocessing ===\n",
    "processed = 0\n",
    "skipped = 0\n",
    "results = []\n",
    "\n",
    "for scan_id in tqdm(scan_ids):\n",
    "    t1_path = os.path.join(raw_path, f\"{scan_id}_T1.nii\")\n",
    "    lesion_path = os.path.join(raw_path, f\"{scan_id}_Lesion.nii\")\n",
    "\n",
    "    t1_out = os.path.join(save_path, f\"{scan_id}_T1.pt\")\n",
    "    lesion_out = os.path.join(save_path, f\"{scan_id}_Lesion.pt\")\n",
    "\n",
    "    if os.path.exists(t1_out) and os.path.exists(lesion_out):\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # === Use advanced preprocessing ===\n",
    "        scan_tensor, mask_tensor = advanced_preprocess_scan(t1_path, lesion_path, target_shape=target_shape, device=device)\n",
    "\n",
    "        # Save processed tensors\n",
    "        torch.save(scan_tensor.cpu(), t1_out)\n",
    "        if mask_tensor is not None:\n",
    "            torch.save(mask_tensor.cpu(), lesion_out)\n",
    "\n",
    "        processed += 1\n",
    "\n",
    "        # (Optional) store stats for logging/debugging\n",
    "        stats = {\n",
    "            \"scan_id\": scan_id,\n",
    "            \"mean\": scan_tensor.mean().item(),\n",
    "            \"std\": scan_tensor.std().item(),\n",
    "            \"lesion_voxels\": mask_tensor.sum().item() if mask_tensor is not None else 0,\n",
    "        }\n",
    "        results.append(stats)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {scan_id}: {e}\")\n",
    "\n",
    "print(f\"\\n✅ Finished preprocessing: {processed} scans processed, {skipped} skipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eanQN6tWRupd",
   "metadata": {
    "id": "eanQN6tWRupd"
   },
   "source": [
    "### View and Save Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "net7Tu5bRx-w",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:51.039721Z",
     "iopub.status.busy": "2025-06-28T21:11:51.039535Z",
     "iopub.status.idle": "2025-06-28T21:11:51.049086Z",
     "shell.execute_reply": "2025-06-28T21:11:51.048281Z",
     "shell.execute_reply.started": "2025-06-28T21:11:51.039707Z"
    },
    "id": "net7Tu5bRx-w",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# results_df = pd.DataFrame(results)\n",
    "# results_df.sort_values(\"scan_std\", ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4OO5FlLQR2Mg",
   "metadata": {
    "id": "4OO5FlLQR2Mg"
   },
   "source": [
    "### Show Noisy Scan IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joYt7KKnR4q0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:51.050633Z",
     "iopub.status.busy": "2025-06-28T21:11:51.049927Z",
     "iopub.status.idle": "2025-06-28T21:11:51.065143Z",
     "shell.execute_reply": "2025-06-28T21:11:51.064410Z",
     "shell.execute_reply.started": "2025-06-28T21:11:51.050609Z"
    },
    "id": "joYt7KKnR4q0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# print(f\"⚠️ Total noisy scans detected: {len(noisy_scans)}\\n\")\n",
    "# print(\"Some examples:\")\n",
    "# print(noisy_scans[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cKh9WfwGc1nk",
   "metadata": {
    "id": "cKh9WfwGc1nk"
   },
   "source": [
    "## Import the preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "J4gK6qRsc_2q",
   "metadata": {
    "id": "J4gK6qRsc_2q"
   },
   "source": [
    "### Extract scan IDs from challenge files folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mGnTDwFxbZA1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:51.066164Z",
     "iopub.status.busy": "2025-06-28T21:11:51.065923Z",
     "iopub.status.idle": "2025-06-28T21:11:51.081517Z",
     "shell.execute_reply": "2025-06-28T21:11:51.080814Z",
     "shell.execute_reply.started": "2025-06-28T21:11:51.066148Z"
    },
    "id": "mGnTDwFxbZA1",
    "outputId": "4561a5c3-698f-4229-a757-b3a6bc08362c",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "all_files = os.listdir(raw_path)\n",
    "scan_ids = sorted(list(set('_'.join(f.split('_')[:-1]) for f in all_files if f.endswith(\"_T1.nii\"))))\n",
    "\n",
    "print(f\"Found {len(scan_ids)} scan IDs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_4LY3tNOdCfu",
   "metadata": {
    "id": "_4LY3tNOdCfu"
   },
   "source": [
    "### Function to load preprocessed tensors for a scan ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saQL4FDJdFyK",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:51.082553Z",
     "iopub.status.busy": "2025-06-28T21:11:51.082306Z",
     "iopub.status.idle": "2025-06-28T21:11:51.093805Z",
     "shell.execute_reply": "2025-06-28T21:11:51.093116Z",
     "shell.execute_reply.started": "2025-06-28T21:11:51.082531Z"
    },
    "id": "saQL4FDJdFyK",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_preprocessed(scan_id):\n",
    "    t1_path = os.path.join(save_path, f\"{scan_id}_T1.pt\")\n",
    "    lesion_path = os.path.join(save_path, f\"{scan_id}_Lesion.pt\")\n",
    "\n",
    "    scan_tensor = None\n",
    "    lesion_tensor = None\n",
    "\n",
    "    if os.path.exists(t1_path):\n",
    "        scan_tensor = torch.load(t1_path)\n",
    "    else:\n",
    "        print(f\"Warning: Preprocessed T1 scan not found for {scan_id}\")\n",
    "\n",
    "    if os.path.exists(lesion_path):\n",
    "        lesion_tensor = torch.load(lesion_path)\n",
    "\n",
    "    return scan_tensor, lesion_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PSd4EFUrdJrq",
   "metadata": {
    "id": "PSd4EFUrdJrq"
   },
   "source": [
    "### Load the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t1qsPd7bdMMg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:51.094824Z",
     "iopub.status.busy": "2025-06-28T21:11:51.094589Z",
     "iopub.status.idle": "2025-06-28T21:11:54.941688Z",
     "shell.execute_reply": "2025-06-28T21:11:54.940895Z",
     "shell.execute_reply.started": "2025-06-28T21:11:51.094798Z"
    },
    "id": "t1qsPd7bdMMg",
    "outputId": "22723937-be88-45b3-f515-b905320a2896",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_single(scan_id):\n",
    "    return scan_id, load_preprocessed(scan_id)\n",
    "\n",
    "all_preprocessed_data = {}\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = [executor.submit(load_single, sid) for sid in scan_ids]\n",
    "    for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "        scan_id, (scan_tensor, lesion_tensor) = future.result()\n",
    "        if scan_tensor is not None and lesion_tensor is not None and lesion_tensor.sum() > 0:\n",
    "            all_preprocessed_data[scan_id] = {\n",
    "                \"scan\": scan_tensor,\n",
    "                \"lesion\": lesion_tensor\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fO82ONq2mp5z",
   "metadata": {
    "id": "fO82ONq2mp5z"
   },
   "source": [
    "### Visualize the processed scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "M1RMBveMmsVh",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:54.942864Z",
     "iopub.status.busy": "2025-06-28T21:11:54.942581Z",
     "iopub.status.idle": "2025-06-28T21:11:54.952267Z",
     "shell.execute_reply": "2025-06-28T21:11:54.951663Z",
     "shell.execute_reply.started": "2025-06-28T21:11:54.942842Z"
    },
    "id": "M1RMBveMmsVh",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def show_multiple_slices(scan_tensor, lesion_tensor=None, axis=0, start_idx=0, num_slices=20):\n",
    "    scan_np = scan_tensor.squeeze().cpu().numpy()\n",
    "    if lesion_tensor is not None:\n",
    "        lesion_np = lesion_tensor.squeeze().cpu().numpy()\n",
    "\n",
    "    max_idx = scan_np.shape[axis] - 1\n",
    "    end_idx = min(start_idx + num_slices, max_idx + 1)  # +1 because slicing is exclusive\n",
    "\n",
    "    slices_to_show = end_idx - start_idx\n",
    "    cols = 5  # Number of columns in the grid\n",
    "    rows = (slices_to_show + cols - 1) // cols  # Compute rows needed\n",
    "\n",
    "    plt.figure(figsize=(cols * 3, rows * 3))\n",
    "\n",
    "    for i, slice_idx in enumerate(range(start_idx, end_idx)):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        if axis == 0:\n",
    "            scan_slice = scan_np[slice_idx, :, :]\n",
    "            lesion_slice = lesion_np[slice_idx, :, :] if lesion_tensor is not None else None\n",
    "        elif axis == 1:\n",
    "            scan_slice = scan_np[:, slice_idx, :]\n",
    "            lesion_slice = lesion_np[:, slice_idx, :] if lesion_tensor is not None else None\n",
    "        elif axis == 2:\n",
    "            scan_slice = scan_np[:, :, slice_idx]\n",
    "            lesion_slice = lesion_np[:, :, slice_idx] if lesion_tensor is not None else None\n",
    "        else:\n",
    "            raise ValueError(\"Axis must be 0, 1, or 2\")\n",
    "\n",
    "        plt.imshow(scan_slice, cmap='gray')\n",
    "        if lesion_tensor is not None:\n",
    "            plt.imshow(lesion_slice, cmap='Reds', alpha=0.4)\n",
    "        plt.title(f\"Slice {slice_idx}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DVDJmbxinMbs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 882
    },
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:54.953064Z",
     "iopub.status.busy": "2025-06-28T21:11:54.952835Z",
     "iopub.status.idle": "2025-06-28T21:11:56.819111Z",
     "shell.execute_reply": "2025-06-28T21:11:56.818270Z",
     "shell.execute_reply.started": "2025-06-28T21:11:54.953048Z"
    },
    "id": "DVDJmbxinMbs",
    "outputId": "4cc2eef9-c6c1-417e-fa12-1a3d5a09297d",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Example: show one preprocessed scan with lesion\n",
    "scan_id = list(all_preprocessed_data.keys())[0]\n",
    "scan_tensor = all_preprocessed_data[scan_id][\"scan\"]\n",
    "lesion_tensor = all_preprocessed_data[scan_id][\"lesion\"]\n",
    "\n",
    "print(scan_tensor.shape)  # should be [1, D, H, W]\n",
    "\n",
    "\n",
    "show_multiple_slices(scan_tensor, lesion_tensor, axis=2, start_idx=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yNDo1r4ip7uL",
   "metadata": {
    "id": "yNDo1r4ip7uL"
   },
   "source": [
    "### Visualize 3d lesions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mAPkq9ZunOL8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:56.820247Z",
     "iopub.status.busy": "2025-06-28T21:11:56.819994Z",
     "iopub.status.idle": "2025-06-28T21:11:56.828139Z",
     "shell.execute_reply": "2025-06-28T21:11:56.827434Z",
     "shell.execute_reply.started": "2025-06-28T21:11:56.820228Z"
    },
    "id": "mAPkq9ZunOL8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_3d_lesion(scan_tensor, lesion_tensor, threshold=0.5):\n",
    "    scan_np = scan_tensor.squeeze().cpu().numpy()\n",
    "    lesion_np = lesion_tensor.squeeze().cpu().numpy()\n",
    "\n",
    "    # Create an isosurface for the lesion mask\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Lesion isosurface\n",
    "    # fig.add_trace(go.Isosurface(\n",
    "    #     x=np.arange(lesion_np.shape[0]),\n",
    "    #     y=np.arange(lesion_np.shape[1]),\n",
    "    #     z=np.arange(lesion_np.shape[2]),\n",
    "    #     value=lesion_np,\n",
    "    #     isomin=0.01,\n",
    "    #     isomax=1,\n",
    "    #     surface_count=1,\n",
    "    #     colorscale='Reds',\n",
    "    #     opacity=0.9,\n",
    "    #     caps=dict(x_show=False, y_show=False, z_show=False),\n",
    "    #     name='Lesion'\n",
    "    # ))\n",
    "\n",
    "    # Optionally, add scan volume (e.g. low opacity)\n",
    "    fig.add_trace(go.Volume(\n",
    "        x=np.arange(lesion_np.shape[0]),\n",
    "        y=np.arange(lesion_np.shape[1]),\n",
    "        z=np.arange(lesion_np.shape[2]),\n",
    "        value=lesion_np,\n",
    "        opacity=0.5,        # Adjust for visibility\n",
    "        surface_count=15,   # Number of isosurfaces inside the volume\n",
    "        colorscale='Reds',\n",
    "        name='Lesion Volume'\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(scene=dict(\n",
    "        xaxis_title='X',\n",
    "        yaxis_title='Y',\n",
    "        zaxis_title='Z'),\n",
    "        title=\"3D Lesion Visualization\"\n",
    "    )\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ipkpq8guqHWV",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:56.829110Z",
     "iopub.status.busy": "2025-06-28T21:11:56.828893Z",
     "iopub.status.idle": "2025-06-28T21:11:56.850643Z",
     "shell.execute_reply": "2025-06-28T21:11:56.849898Z",
     "shell.execute_reply.started": "2025-06-28T21:11:56.829094Z"
    },
    "id": "Ipkpq8guqHWV",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# scan_id = list(all_preprocessed_data.keys())[0]\n",
    "# scan_tensor = all_preprocessed_data[scan_id][\"scan\"]\n",
    "# lesion_tensor = all_preprocessed_data[scan_id][\"lesion\"]\n",
    "\n",
    "# # Convert tensors to numpy for inspection\n",
    "# scan_np = scan_tensor.squeeze().cpu().numpy()\n",
    "# lesion_np = lesion_tensor.squeeze().cpu().numpy()\n",
    "\n",
    "# print(\"Scan shape:\", scan_np.shape, \"Min:\", scan_np.min(), \"Max:\", scan_np.max())\n",
    "# print(\"Lesion shape:\", lesion_np.shape, \"Min:\", lesion_np.min(), \"Max:\", lesion_np.max())\n",
    "\n",
    "# print(\"Lesion voxel count:\", (lesion_np > 0.1).sum())\n",
    "\n",
    "# plot_3d_lesion(scan_tensor, lesion_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ePgxiFBBCYLy",
   "metadata": {
    "id": "ePgxiFBBCYLy"
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "J17MuN8vCaKF",
   "metadata": {
    "id": "J17MuN8vCaKF"
   },
   "source": [
    "### Defining the class for creating Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AZgHAX5tCX67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:56.851702Z",
     "iopub.status.busy": "2025-06-28T21:11:56.851404Z",
     "iopub.status.idle": "2025-06-28T21:11:56.867477Z",
     "shell.execute_reply": "2025-06-28T21:11:56.866903Z",
     "shell.execute_reply.started": "2025-06-28T21:11:56.851686Z"
    },
    "id": "AZgHAX5tCX67",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TBI3DSegmentationDataset(Dataset):\n",
    "    def __init__(self, data_dict, transform=None):\n",
    "        self.ids = list(data_dict.keys())\n",
    "        self.data = data_dict\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        scan_id = self.ids[idx]\n",
    "        scan = self.data[scan_id][\"scan\"]\n",
    "        lesion = self.data[scan_id][\"lesion\"]\n",
    "\n",
    "        # Ensure shape is (C, D, H, W)\n",
    "        scan = scan.squeeze()  # remove extra dims if any\n",
    "        lesion = lesion.squeeze()\n",
    "\n",
    "        scan = scan.unsqueeze(0)\n",
    "        lesion = lesion.unsqueeze(0)\n",
    "\n",
    "        if self.transform:\n",
    "            scan, lesion = self.transform(scan, lesion)\n",
    "\n",
    "        return scan, lesion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BnQQP9PyCnp2",
   "metadata": {
    "id": "BnQQP9PyCnp2"
   },
   "source": [
    "### Split Train/Val + Create Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YXVihiKvDJp4",
   "metadata": {
    "id": "YXVihiKvDJp4"
   },
   "source": [
    "### 3DUNET Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2Vk11rRzDMYr",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:56.868386Z",
     "iopub.status.busy": "2025-06-28T21:11:56.868149Z",
     "iopub.status.idle": "2025-06-28T21:11:56.885445Z",
     "shell.execute_reply": "2025-06-28T21:11:56.884793Z",
     "shell.execute_reply.started": "2025-06-28T21:11:56.868365Z"
    },
    "id": "2Vk11rRzDMYr",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DoubleConv3D(nn.Module):\n",
    "    \"\"\"(Conv3D => BN => ReLU) * 2\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, features=[32, 64, 128, 256]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Down path\n",
    "        for feature in features:\n",
    "            self.encoder.append(DoubleConv3D(in_channels, feature))\n",
    "            in_channels = feature\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = DoubleConv3D(features[-1], features[-1]*2)\n",
    "\n",
    "        # Up path\n",
    "        self.up_transpose = nn.ModuleList()\n",
    "        self.decoder = nn.ModuleList()\n",
    "        reversed_features = features[::-1]\n",
    "\n",
    "        for feature in reversed_features:\n",
    "            self.up_transpose.append(\n",
    "                nn.ConvTranspose3d(feature*2, feature, kernel_size=2, stride=2)\n",
    "            )\n",
    "            self.decoder.append(\n",
    "                DoubleConv3D(feature*2, feature)\n",
    "            )\n",
    "\n",
    "        # Final layer\n",
    "        self.final_conv = nn.Conv3d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "\n",
    "        # Downsampling\n",
    "        for down in self.encoder:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        # Upsampling\n",
    "        for i in range(len(self.up_transpose)):\n",
    "            x = self.up_transpose[i](x)\n",
    "            skip = skip_connections[i]\n",
    "\n",
    "            if x.shape != skip.shape:\n",
    "                # Ensure spatial alignment\n",
    "                x = F.interpolate(x, size=skip.shape[2:])\n",
    "\n",
    "            x = torch.cat((skip, x), dim=1)\n",
    "            x = self.decoder[i](x)\n",
    "\n",
    "        return self.final_conv(x)  # logits, use with BCEWithLogitsLoss or sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1618a2a5",
   "metadata": {},
   "source": [
    "Improved 3DUnet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998471e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:56.886330Z",
     "iopub.status.busy": "2025-06-28T21:11:56.886130Z",
     "iopub.status.idle": "2025-06-28T21:11:56.906589Z",
     "shell.execute_reply": "2025-06-28T21:11:56.905940Z",
     "shell.execute_reply.started": "2025-06-28T21:11:56.886315Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AttentionGate3D(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv3d(F_g, F_int, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm3d(F_int)\n",
    "        )\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv3d(F_l, F_int, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm3d(F_int)\n",
    "        )\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv3d(F_int, 1, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm3d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        return x * psi\n",
    "\n",
    "class ImprovedUNet3D(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, features=[32, 64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        \n",
    "        for feature in features:\n",
    "            self.encoder.append(DoubleConv3D(in_channels, feature))\n",
    "            in_channels = feature\n",
    "        \n",
    "        # Bottleneck with dropout\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            DoubleConv3D(features[-1], features[-1]*2),\n",
    "            nn.Dropout3d(0.5)\n",
    "        )\n",
    "        \n",
    "        # Decoder with attention gates\n",
    "        self.up_transpose = nn.ModuleList()\n",
    "        self.attention_gates = nn.ModuleList()\n",
    "        self.decoder = nn.ModuleList()\n",
    "        \n",
    "        reversed_features = features[::-1]\n",
    "        for i, feature in enumerate(reversed_features):\n",
    "            self.up_transpose.append(\n",
    "                nn.ConvTranspose3d(feature*2, feature, kernel_size=2, stride=2)\n",
    "            )\n",
    "            self.attention_gates.append(\n",
    "                AttentionGate3D(feature, feature, feature//2)\n",
    "            )\n",
    "            self.decoder.append(DoubleConv3D(feature*2, feature))\n",
    "        \n",
    "        # Final layers with deep supervision\n",
    "        self.final_conv = nn.Conv3d(features[0], out_channels, kernel_size=1)\n",
    "        \n",
    "        # Deep supervision outputs\n",
    "        self.deep_outputs = nn.ModuleList([\n",
    "            nn.Conv3d(feat, out_channels, kernel_size=1) \n",
    "            for feat in reversed_features[:-1]\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "        \n",
    "        # Encoder\n",
    "        for down in self.encoder:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "        \n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "        \n",
    "        deep_outputs = []\n",
    "        \n",
    "        # Decoder with attention\n",
    "        for i in range(len(self.up_transpose)):\n",
    "            x = self.up_transpose[i](x)\n",
    "            skip = skip_connections[i]\n",
    "            \n",
    "            # Attention gate\n",
    "            skip = self.attention_gates[i](x, skip)\n",
    "            \n",
    "            if x.shape != skip.shape:\n",
    "                x = F.interpolate(x, size=skip.shape[2:])\n",
    "            \n",
    "            x = torch.cat((skip, x), dim=1)\n",
    "            x = self.decoder[i](x)\n",
    "            \n",
    "            # Deep supervision\n",
    "            if i < len(self.deep_outputs):\n",
    "                deep_out = self.deep_outputs[i](x)\n",
    "                deep_outputs.append(deep_out)\n",
    "        \n",
    "        main_output = self.final_conv(x)\n",
    "        \n",
    "        if self.training:\n",
    "            return main_output, deep_outputs\n",
    "        else:\n",
    "            return main_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WzlHGj_mDnix",
   "metadata": {
    "id": "WzlHGj_mDnix"
   },
   "source": [
    "### Initialize Model, Loss, Optimizer, Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ORQA8ZhUyKYq",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:56.907631Z",
     "iopub.status.busy": "2025-06-28T21:11:56.907312Z",
     "iopub.status.idle": "2025-06-28T21:11:56.924154Z",
     "shell.execute_reply": "2025-06-28T21:11:56.923428Z",
     "shell.execute_reply.started": "2025-06-28T21:11:56.907616Z"
    },
    "id": "ORQA8ZhUyKYq",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SoftDiceLoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        preds = torch.sigmoid(preds)\n",
    "        intersection = (preds * targets).sum()\n",
    "        union = preds.sum() + targets.sum()\n",
    "        dice = (2. * intersection + self.eps) / (union + self.eps)\n",
    "        return 1 - dice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50980143",
   "metadata": {},
   "source": [
    "Advanced Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6717500b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:56.928166Z",
     "iopub.status.busy": "2025-06-28T21:11:56.927878Z",
     "iopub.status.idle": "2025-06-28T21:11:56.938165Z",
     "shell.execute_reply": "2025-06-28T21:11:56.937410Z",
     "shell.execute_reply.started": "2025-06-28T21:11:56.928150Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FocalTverskyLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.7, beta=0.3, gamma=2.0, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "        \n",
    "        # Flatten for calculation\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        # True Positives, False Positives & False Negatives\n",
    "        tp = (inputs * targets).sum()\n",
    "        fp = ((1 - targets) * inputs).sum()\n",
    "        fn = (targets * (1 - inputs)).sum()\n",
    "        \n",
    "        tversky = (tp + self.smooth) / (tp + self.alpha * fp + self.beta * fn + self.smooth)\n",
    "        focal_tversky = torch.pow((1 - tversky), self.gamma)\n",
    "        \n",
    "        return focal_tversky\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(50.0))\n",
    "        self.dice = SoftDiceLoss()\n",
    "        self.focal_tversky = FocalTverskyLoss()\n",
    "    \n",
    "    def forward(self, outputs, targets, deep_outputs=None):\n",
    "        main_loss = (0.3 * self.bce(outputs, targets) + \n",
    "                    0.4 * self.dice(outputs, targets) + \n",
    "                    0.3 * self.focal_tversky(outputs, targets))\n",
    "        \n",
    "        # Deep supervision loss\n",
    "        if deep_outputs is not None:\n",
    "            deep_loss = 0\n",
    "            for deep_out in deep_outputs:\n",
    "                # Resize deep output to match target\n",
    "                deep_resized = F.interpolate(deep_out, size=targets.shape[2:], mode='trilinear')\n",
    "                deep_loss += self.dice(deep_resized, targets)\n",
    "            main_loss += 0.2 * deep_loss / len(deep_outputs)\n",
    "        \n",
    "        return main_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17925cb6-c96d-4bde-a706-87e84a6408ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:56.939226Z",
     "iopub.status.busy": "2025-06-28T21:11:56.938936Z",
     "iopub.status.idle": "2025-06-28T21:11:56.955831Z",
     "shell.execute_reply": "2025-06-28T21:11:56.955077Z",
     "shell.execute_reply.started": "2025-06-28T21:11:56.939199Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Mixed precision training\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "def train_epoch_improved(model, train_loader, criterion, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_dice = 0.0\n",
    "    \n",
    "    for scans, masks in tqdm(train_loader, desc=\"Training\"):\n",
    "        scans, masks = scans.to(device), masks.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            if hasattr(model, 'training') and model.training:\n",
    "                outputs, deep_outputs = model(scans)\n",
    "                loss = criterion(outputs, masks, deep_outputs)\n",
    "            else:\n",
    "                outputs = model(scans)\n",
    "                loss = criterion(outputs, masks)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_dice += dice_coefficient(outputs, masks)\n",
    "    \n",
    "    return total_loss / len(train_loader), total_dice / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8eb06e-b4bc-4924-bd17-4526e35847a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:56.956983Z",
     "iopub.status.busy": "2025-06-28T21:11:56.956698Z",
     "iopub.status.idle": "2025-06-28T21:11:56.974128Z",
     "shell.execute_reply": "2025-06-28T21:11:56.973318Z",
     "shell.execute_reply.started": "2025-06-28T21:11:56.956941Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def dice_coefficient(preds, targets, threshold=0.3, eps=1e-6):\n",
    "    with torch.no_grad():\n",
    "        preds = torch.sigmoid(preds)\n",
    "        preds = (preds > threshold).float()\n",
    "\n",
    "        intersection = (preds * targets).sum(dim=(1, 2, 3, 4))\n",
    "        union = preds.sum(dim=(1, 2, 3, 4)) + targets.sum(dim=(1, 2, 3, 4))\n",
    "\n",
    "        dice = (2. * intersection + eps) / (union + eps)\n",
    "        return dice.mean().item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b1358b",
   "metadata": {},
   "source": [
    "### Optuna Hyperparameter Optimization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc806727",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:56.975597Z",
     "iopub.status.busy": "2025-06-28T21:11:56.975070Z",
     "iopub.status.idle": "2025-06-28T21:11:56.987564Z",
     "shell.execute_reply": "2025-06-28T21:11:56.987029Z",
     "shell.execute_reply.started": "2025-06-28T21:11:56.975579Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Sample hyperparameters\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-3, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-3, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [1, 2, 4])\n",
    "\n",
    "    # Create train/val split INSIDE the function\n",
    "    full_dataset = TBI3DSegmentationDataset(all_preprocessed_data)\n",
    "    train_size = int(0.9 * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    train_ds, val_ds = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    # Model and optimizer\n",
    "    model = ImprovedUNet3D(in_channels=1, out_channels=1).to(device)\n",
    "    criterion = CombinedLoss().to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    # Train for 1 epoch (or more for better results)\n",
    "    train_epoch_improved(model, train_loader, criterion, optimizer, scaler, device)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_dice = 0.0\n",
    "    with torch.no_grad():\n",
    "        for scans, masks in val_loader:\n",
    "            scans, masks = scans.to(device), masks.to(device)\n",
    "            result = model(scans)\n",
    "            if isinstance(result, tuple):\n",
    "                outputs, _ = result\n",
    "            else:\n",
    "                outputs = result\n",
    "            val_dice += dice_coefficient(outputs, masks)\n",
    "    avg_val_dice = val_dice / len(val_loader)\n",
    "    return avg_val_dice  # Optuna will maximize this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae46a4fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T21:11:56.988521Z",
     "iopub.status.busy": "2025-06-28T21:11:56.988261Z",
     "iopub.status.idle": "2025-06-28T21:46:57.209905Z",
     "shell.execute_reply": "2025-06-28T21:46:57.209042Z",
     "shell.execute_reply.started": "2025-06-28T21:11:56.988494Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=5)  # You can increase n_trials for a more thorough search\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best Dice score:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hkGbg82oDo3J",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-28T21:46:57.211980Z",
     "iopub.status.busy": "2025-06-28T21:46:57.211201Z",
     "iopub.status.idle": "2025-06-28T21:46:58.069768Z",
     "shell.execute_reply": "2025-06-28T21:46:58.068912Z",
     "shell.execute_reply.started": "2025-06-28T21:46:57.211932Z"
    },
    "id": "hkGbg82oDo3J",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "best_lr = study.best_params['lr']\n",
    "best_weight_decay = study.best_params['weight_decay']\n",
    "best_batch_size = study.best_params['batch_size']\n",
    "\n",
    "# Device config\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path = \"lesion_fix_optuna_unet3d_model.pt\"\n",
    "\n",
    "# Create proper train/val split\n",
    "full_dataset = TBI3DSegmentationDataset(all_preprocessed_data)\n",
    "train_size = int(0.9 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_ds, val_ds = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# Data loaders\n",
    "# Data loaders with best batch size\n",
    "train_loader = DataLoader(train_ds, batch_size=best_batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_ds, batch_size=best_batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Model and optimizer with best hyperparameters\n",
    "model = ImprovedUNet3D(in_channels=1, out_channels=1).to(device)\n",
    "criterion = CombinedLoss().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=best_lr, weight_decay=best_weight_decay)\n",
    "# Remove conflicting schedulers and use only this:\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='max',          # Monitor for maximum (Dice score)\n",
    "    factor=0.5,          # Reduce LR by half\n",
    "    patience=5,          # Wait 5 epochs before reducing\n",
    "    min_lr=1e-7,         # Minimum learning rate\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Training variables\n",
    "best_dice = 0.0\n",
    "trigger_times = 0\n",
    "patience = 10\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jhkAawvDD7jg",
   "metadata": {
    "id": "jhkAawvDD7jg",
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "KZN8_QgKECCQ",
   "metadata": {
    "id": "KZN8_QgKECCQ"
   },
   "source": [
    "### Training + Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KkaP-hbZEC9L",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-28T21:46:58.071437Z",
     "iopub.status.busy": "2025-06-28T21:46:58.070713Z"
    },
    "id": "KkaP-hbZEC9L",
    "outputId": "76ff3209-40ad-4621-98b0-776735005e92",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "train_dice_list = []\n",
    "val_dice_list = []\n",
    "\n",
    "# Mixed precision training\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "print(f\"Starting training with {len(train_loader)} training batches and {len(val_loader)} validation batches\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_dice = 0.0\n",
    "\n",
    "    for scans, masks in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n",
    "        scans, masks = scans.to(device), masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Use mixed precision training\n",
    "        with torch.cuda.amp.autocast():\n",
    "            # Handle both basic and improved UNet\n",
    "            if isinstance(model, ImprovedUNet3D):\n",
    "                outputs, deep_outputs = model(scans)\n",
    "                loss = criterion(outputs, masks, deep_outputs)\n",
    "            else:\n",
    "                outputs = model(scans)\n",
    "                loss = criterion(outputs, masks)\n",
    "\n",
    "        # Mixed precision backward pass\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_dice += dice_coefficient(outputs, masks)\n",
    "\n",
    "    # Calculate averages - FIX: Complete the calculation\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    avg_train_dice = total_dice / len(train_loader)\n",
    "    train_loss_list.append(avg_train_loss)\n",
    "    train_dice_list.append(avg_train_dice)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_dice = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for scans, masks in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\"):\n",
    "            scans, masks = scans.to(device), masks.to(device)\n",
    "\n",
    "            # FIX: Handle dual output in validation too\n",
    "            result = model(scans)\n",
    "            if isinstance(result, tuple):\n",
    "                outputs, deep_outputs = result\n",
    "                loss = criterion(outputs, masks, deep_outputs)\n",
    "            else:\n",
    "                outputs = result\n",
    "                loss = criterion(outputs, masks)\n",
    "\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_dice += dice_coefficient(outputs, masks)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    avg_val_dice = val_dice / len(val_loader)\n",
    "    val_loss_list.append(avg_val_loss)\n",
    "    val_dice_list.append(avg_val_dice)\n",
    "\n",
    "    # Scheduler step\n",
    "    scheduler.step(avg_val_dice)\n",
    "\n",
    "    # Logging\n",
    "    print(f\"\\n📊 Epoch {epoch+1}/{num_epochs} Summary:\")\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f} | Dice: {avg_train_dice:.4f}\")\n",
    "    print(f\"Val   Loss: {avg_val_loss:.4f} | Dice: {avg_val_dice:.4f}\")\n",
    "    print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "    # Save best model\n",
    "    if avg_val_dice > best_dice:\n",
    "        best_dice = avg_val_dice\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f\"✅ Saved best model at epoch {epoch+1} with Dice: {best_dice:.4f}\")\n",
    "        trigger_times = 0\n",
    "\n",
    "        # Save training stats\n",
    "        stats_path = model_path.replace('.pt', '.txt')\n",
    "        with open(stats_path, 'w') as f:\n",
    "            f.write(f\"Best Epoch: {epoch+1}\\n\")\n",
    "            f.write(f\"Best Val Dice: {best_dice:.4f}\\n\\n\")\n",
    "            f.write(\"Epoch\\tTrain Loss\\tVal Loss\\tTrain Dice\\tVal Dice\\n\")\n",
    "            for i in range(epoch + 1):\n",
    "                f.write(f\"{i+1}\\t{train_loss_list[i]:.4f}\\t{val_loss_list[i]:.4f}\\t\"\n",
    "                        f\"{train_dice_list[i]:.4f}\\t{val_dice_list[i]:.4f}\\n\")\n",
    "\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        print(f\"⚠️ No improvement. Patience counter: {trigger_times}/{patience}\")\n",
    "\n",
    "        if trigger_times >= patience:\n",
    "            print(\"🛑 Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(f\"\\n🎉 Training completed! Best Dice score: {best_dice:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g0k6SHF0EKgc",
   "metadata": {
    "id": "g0k6SHF0EKgc"
   },
   "source": [
    "### Import the model from drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-1b_0SbxEJ0k",
   "metadata": {
    "id": "-1b_0SbxEJ0k",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model = UNet3D(in_channels=1, out_channels=1)\n",
    "# model.load_state_dict(torch.load(model_path))\n",
    "# model.to(device)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e6c7c8-1a8a-4a1d-ada6-67f1718c0e87",
   "metadata": {},
   "source": [
    "### Download Saved Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4f41b8-a2c2-492f-a34f-7a2b6e89c956",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!zip -r PreprocessedData.zip /kaggle/working/PreprocessedData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb32d541-5caa-48da-8e10-57a8435303cb",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(\"PreprocessedData.zip\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7741510,
     "sourceId": 12283891,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
